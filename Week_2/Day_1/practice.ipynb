{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc8c39d",
   "metadata": {},
   "source": [
    "# Frontier Model APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0311e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import dotenv\n",
    "import requests\n",
    "\n",
    "from openai import OpenAI\n",
    "import ollama\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d88eff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT model\n",
    "MODEL_GPT = \"gpt-4o-mini\"\n",
    "MODEL_LLAMA = \"llama3.2:latest\"\n",
    "MODEL_DEEPSEEK = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017652cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-is-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be106823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xin chào! Tôi là một chương trình máy tính, nên tôi không có cảm giác về sức khỏe như con người. Tôi luôn sẵn sàng giúp đỡ và hỗ trợ bạn trong mọi vấn đề bạn có thể gặp phải! Bạn cần giúp đỡ gì today?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response_o = ollama.chat(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Bạn là trợ lý hữu ích.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Xin chào, bạn có khoẻ không?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response_o[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc7f00b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hãy vui yêu cầu của bạn! Tôi là một người thay đổi và luôn active, muốn bạn giúp tôi hiểu hơn về việc này. Xin盒子 vui!\n"
     ]
    }
   ],
   "source": [
    "# DeepSeek\n",
    "response_ds = ollama.chat(\n",
    "    model=MODEL_DEEPSEEK,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Bạn là trợ lý hữu ích.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Xin chào, bạn có khoẻ không?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response_ds[\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
