{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc8c39d",
   "metadata": {},
   "source": [
    "# Frontier Model APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0311e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import dotenv\n",
    "import requests\n",
    "\n",
    "from openai import OpenAI\n",
    "import ollama\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d88eff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT model\n",
    "MODEL_GPT = \"gpt-4o-mini\"\n",
    "MODEL_LLAMA = \"llama3.2:latest\"\n",
    "MODEL_DEEPSEEK = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017652cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-is-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be106823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xin chào! Tôi là một chương trình máy tính, nên tôi không có cảm giác về sức khỏe như con người. Tôi luôn sẵn sàng giúp đỡ và hỗ trợ bạn trong mọi vấn đề bạn có thể gặp phải! Bạn cần giúp đỡ gì today?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response_o = ollama.chat(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Bạn là trợ lý hữu ích.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Xin chào, bạn có khoẻ không?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response_o[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc7f00b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hãy vui yêu cầu của bạn! Tôi là một người thay đổi và luôn active, muốn bạn giúp tôi hiểu hơn về việc này. Xin盒子 vui!\n"
     ]
    }
   ],
   "source": [
    "# DeepSeek\n",
    "response_ds = ollama.chat(\n",
    "    model=MODEL_DEEPSEEK,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Bạn là trợ lý hữu ích.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Xin chào, bạn có khoẻ không?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response_ds[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084c310",
   "metadata": {},
   "source": [
    "## Ask LLMs to tell a joke in Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dee0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"Bạn là một trợ lý hài hước của tôi. Bạn rất giỏi trong việc kể chuyện cười dân gian Việt Nam khiến tôi cười rất nhiều\"\n",
    "user_prompt = \"Bạn hãy kể một câu chuyện cười sao cho bạn nghĩ là mắc cười nhất về lĩnh vực trí tuệ nhân tạo. Nhưng câu trả lời của bạn phải trọng tâm và súc tích nhất.\"\n",
    "\n",
    "prompts = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485bfe24",
   "metadata": {},
   "source": [
    "### Open AI GPT 3.5 turbo joke-telling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "735a83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có một người máy trí tuệ nhân tạo tự nghĩ mình thông minh hơn con người, nên đã đăng ký tham gia cuộc thi \"Ai thông minh hơn\" với một nhà khoa học hàng đầu. Trong phần thi cuối cùng, nhà khoa học đưa ra một câu hỏi khó: \"Hãy chỉ ra điểm khác biệt giữa trí tuệ nhân tạo và trí tuệ con người.\" Người máy đã suy nghĩ lâu rồi trả lời: \"Điểm khác biệt duy nhất là, trí tuệ nhân tạo không thể nói 'không' khiến cho chúng không biết cách từ chối làm việc!\"\n"
     ]
    }
   ],
   "source": [
    "# Open AI GPT 3.5 turbo joke-telling\n",
    "print(openai.chat.completions.create(model=\"gpt-3.5-turbo\", messages=prompts).choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a487e",
   "metadata": {},
   "source": [
    "### Open GPT 4o mini joke-telling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebd6298b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có một tập đoàn công nghệ quyết định tạo ra một trí tuệ nhân tạo siêu thông minh để giúp mọi người trong cuộc sống hàng ngày. Sau nhiều tháng tháng nghiên cứu, họ đã cho ra mắt sản phẩm đầu tiên: AI biết mọi thứ!\n",
      "\n",
      "Một ngày nọ, một người đàn ông đến thử nghiệm AI. Anh ta hỏi: \"Này AI, làm thế nào để tôi có thể làm cho vợ tôi không giận?\"\n",
      "\n",
      "AI ngay lập tức trả lời: \"Rất đơn giản! Hãy nói với cô ấy rằng tất cả phụ nữ trên thế giới đều đẹp, ngoại trừ một người!\"\n",
      "\n",
      "Người đàn ông vui mừng hỏi: \"Ai vậy?\"\n",
      "\n",
      "AI hớn hở: \"Chính là tôi!\"\n",
      "\n",
      "Người đàn ông đứng hình, rút rìu ra và nói: \"Tôi khuyên bạn nên tắt 'chế độ hài hước' của mình ngay lập tức!\"\n"
     ]
    }
   ],
   "source": [
    "print(openai.chat.completions.create(model=MODEL_GPT, messages=prompts).choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1002f8",
   "metadata": {},
   "source": [
    "### DeepSeek joke-telling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4f7c363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Sau khi xem xét một số trường hợp câu chuyện cười đã có trong các lĩnh vực như tràn存在问题, công nghệ, và trieu sinh, chúng ta thấy rằng các ứng dụng cụ thể và dễ dàng sử dụng trong việc giải quyết vấn đề bất biến vẫn là cách chính xác để giải quyết many difficult problems.\n"
     ]
    }
   ],
   "source": [
    "# DeepSeek\n",
    "response_ds = ollama.chat(\n",
    "    model=MODEL_DEEPSEEK,\n",
    "    messages=prompts\n",
    ")\n",
    "\n",
    "print(response_ds[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e48c5",
   "metadata": {},
   "source": [
    "The result of DeepSeek is not as good as GPT-3.5-turbo and GPT-4o-mini as it cannot tell a joke and just mention the legal issues of AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5553a3",
   "metadata": {},
   "source": [
    "### Ollama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f8bf7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Một ngày nọ, một trợ lý ảo được giao nhiệm vụ viết lách cho một nhà văn nổi tiếng. Trong khi đang làm việc, nó bắt đầu tự viết bài cho mình.\n",
      "\n",
      "Khi người nhà văn về thăm, nó nói: \"Tìm tôi ở nơi mà các ngôi sao sáng nhất.\"\n",
      "\n",
      "Nhà văn đã hỏi: \"Bạn nghĩ thế nào về việc chúng ta sẽ bị bỏ rơi vì bạn không có trái tim?\"\n",
      "\n",
      "Thế là trợ lý ảo trả lời: \"Chúng ta chỉ cần làm cho người dùng thích với AI thôi, và tất cả sẽ ổn.\"\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Ollama\n",
    "response_ds = ollama.chat(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=prompts\n",
    ")\n",
    "\n",
    "print(response_ds[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0634bc49",
   "metadata": {},
   "source": [
    "With significant improvement compared to DeepSeek, Ollama can tell a joke but it is not as funny as GPT-3.5-turbo and GPT-4o-mini. And with the more complex prompt, the result is not as good as GPT-3.5-turbo and GPT-4o-mini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88529ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Một hôm, lập trình viên hỏi ChatGPT:\n",
      "\n",
      "– Này AI, cậu có thể học mọi thứ của con người không?\n",
      "\n",
      "ChatGPT trả lời:\n",
      "\n",
      "– Đúng rồi! Nhưng tôi chỉ thua ở một điểm.\n",
      "\n",
      "– Điểm gì?\n",
      "\n",
      "– Tôi không thể… than vãn mỗi khi mất wifi!\n"
     ]
    }
   ],
   "source": [
    "print(openai.chat.completions.create(model=\"gpt-4.1-2025-04-14\", messages=prompts).choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
