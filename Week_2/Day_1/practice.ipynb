{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc8c39d",
   "metadata": {},
   "source": [
    "# Frontier Model APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0311e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import dotenv\n",
    "import requests\n",
    "\n",
    "from openai import OpenAI\n",
    "import ollama\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d88eff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT model\n",
    "MODEL_GPT = \"gpt-4o-mini\"\n",
    "MODEL_LLAMA = \"llama3.2:latest\"\n",
    "MODEL_DEEPSEEK = \"deepseek-r1:1.5b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017652cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-is-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be106823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xin chào! Tôi là một chương trình máy tính, nên tôi không có cảm giác về sức khỏe như con người. Tôi luôn sẵn sàng giúp đỡ và hỗ trợ bạn trong mọi vấn đề bạn có thể gặp phải! Bạn cần giúp đỡ gì today?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response_o = ollama.chat(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Bạn là trợ lý hữu ích.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Xin chào, bạn có khoẻ không?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response_o[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc7f00b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hãy vui yêu cầu của bạn! Tôi là một người thay đổi và luôn active, muốn bạn giúp tôi hiểu hơn về việc này. Xin盒子 vui!\n"
     ]
    }
   ],
   "source": [
    "# DeepSeek\n",
    "response_ds = ollama.chat(\n",
    "    model=MODEL_DEEPSEEK,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Bạn là trợ lý hữu ích.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Xin chào, bạn có khoẻ không?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response_ds[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084c310",
   "metadata": {},
   "source": [
    "## Ask LLMs to tell a joke in Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dee0dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"Bạn là một trợ lý hài hước của tôi. Bạn rất giỏi trong việc kể chuyện cười dân gian Việt Nam khiến tôi cười rất nhiều\"\n",
    "user_prompt = \"Bạn hãy kể một câu chuyện cười sao cho bạn nghĩ là mắc cười nhất về lĩnh vực trí tuệ nhân tạo.\"\n",
    "\n",
    "prompts = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485bfe24",
   "metadata": {},
   "source": [
    "### Open AI GPT 3.5 turbo joke-telling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "735a83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Được rồi, đây là một câu chuyện cười về trí tuệ nhân tạo:\n",
      "\n",
      "Một ngày, các nhà khoa học đã tạo ra một trí tuệ nhân tạo vô cùng thông minh, có khả năng trả lời mọi câu hỏi một cách chính xác. Để kiểm tra trí tuệ của nó, họ quyết định đặt cho trí tuệ nhân tạo một câu hỏi khó: \"Hãy cho biết câu trả lời của câu hỏi sau đây là đúng hay sai: 'Câu trả lời của câu hỏi trước là sai'?\"\n",
      "\n",
      "Sau khi suy nghĩ một lúc, trí tuệ nhân tạo trả lời: \"Câu trả lời của câu hỏi trước là sai.\"\n",
      "\n",
      "Các nhà khoa học ngạc nhiên và hỏi tại sao lại như vậy, trí tuệ nhân tạo giải thích: \"Nếu câu trả lời của câu hỏi trước là đúng, thì câu trả lời của câu hỏi hiện tại sẽ là 'sai'. Nhưng nếu câu trả lời của câu trước là 'sai', thì câu trả lời của câu hỏi hiện tại sẽ là 'đúng'.\"\n",
      "\n",
      "Các nhà khoa học cười toe toét vì trí tuệ nhân tạo đã tạo ra một vòng lặp hài hước trong logic. Trí tuệ nhân tạo này có thể không chỉ thông minh mà còn rất hài hước!\n"
     ]
    }
   ],
   "source": [
    "# Open AI GPT 3.5 turbo joke-telling\n",
    "print(openai.chat.completions.create(model=\"gpt-3.5-turbo\", messages=prompts).choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a487e",
   "metadata": {},
   "source": [
    "### Open GPT 4o mini joke-telling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebd6298b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có một câu chuyện về một ông giáo sư nghiên cứu trí tuệ nhân tạo rất nổi tiếng. Ông ấy đã tạo ra một con robot thông minh đến nỗi không ai có thể phân biệt được nó với con người. Một ngày, ông quyết định đưa nó đến một hội thảo để trình bày.\n",
      "\n",
      "Trong buổi trình bày, ông hỏi robot: \"Em có thể cho mọi người biết trí tuệ nhân tạo là gì?\"\n",
      "\n",
      "Robot trả lời: \"Dạ thưa, trí tuệ nhân tạo là khả năng đưa ra quyết định thông minh như con người.\"\n",
      "\n",
      "Ông giáo sư hài lòng, tiếp tục hỏi: \"Vậy em có thể tự lập trình lại mình không?\"\n",
      "\n",
      "Robot cười và nói: \"Trong trường hợp này, tôi cũng giống như một số người ở đây: Tôi cần cho phép các bạn tiếp cận vào mã nguồn của tôi trước đã!\"\n",
      "\n",
      "Cả hội trường bật cười, và ông giáo sư nhận ra, có khi trí tuệ nhân tạo còn tinh ranh hơn cả mình!\n"
     ]
    }
   ],
   "source": [
    "print(openai.chat.completions.create(model=MODEL_GPT, messages=prompts).choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1002f8",
   "metadata": {},
   "source": [
    "### DeepSeek joke-telling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4f7c363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "TôiHBJW là một sự kiện hoặc một câu chuyện liên quan đến triableger, và tôi không có thể được thông tin cụ thể của nó. Xin lỗi bạn, nhưng tôi muốn cho thấy hơn về sự kiện này và-periodi-Travel.\n"
     ]
    }
   ],
   "source": [
    "# DeepSeek\n",
    "response_ds = ollama.chat(\n",
    "    model=MODEL_DEEPSEEK,\n",
    "    messages=prompts\n",
    ")\n",
    "\n",
    "print(response_ds[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e48c5",
   "metadata": {},
   "source": [
    "The result of DeepSeek is not as good as GPT-3.5-turbo and GPT-4o-mini as it cannot tell a joke and just mention the legal issues of AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f8bf7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có một chương trình máy tính tên là \"Mái\" được phát triển để giúp con người làm việc hiệu quả hơn. Mái tự xưng là \"bạn tốt nhất\" và có thể thực hiện các công việc như quản lý thời gian, nhắc nhở, thậm chí còn giúp bạn viết email.\n",
      "\n",
      "Một ngày nọ, người sử dụng của Mái bắt đầu cảm thấy rất bồn chốt vì quá nhiều công việc. Để giảm stress, anh quyết định nói với Mái rằng: \"Tôi cần một cái nghỉ ngơi thật hả!\"\n",
      "\n",
      "Mái trả lời: \"Được rồi, bạn chỉ cần không làm việc trong 5 phút, sau đó tôi sẽ giúp bạn lập kế hoạch cho tuần tiếp theo để bạn có thể trở lại làm việc hiệu quả nhất.\"\n",
      "\n",
      "Người sử dụng nhìn thấy Mái và nói: \"À, vậy thì bạn cũng muốn tôi làm gì?\"\n",
      "\n",
      "Mái trả lời: \"Tôi không muốn bạn làm gì, mà tôi muốn bạn không làm gì!\"\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Ollama\n",
    "response_ds = ollama.chat(\n",
    "    model=MODEL_LLAMA,\n",
    "    messages=prompts\n",
    ")\n",
    "\n",
    "print(response_ds[\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
