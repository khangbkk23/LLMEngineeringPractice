{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258339e5",
   "metadata": {},
   "source": [
    "# RAG SYSTEM LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4826a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f284f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot find this zipfile.\n"
     ]
    }
   ],
   "source": [
    "# Unzip the data files\n",
    "import zipfile\n",
    "def unzip_file(path, data_dir, delete=True):\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Cannot find this zipfile.\")\n",
    "        return\n",
    "    \n",
    "    if path.endswith(\".zip\"):\n",
    "        with zipfile.ZipFile(path, \"r\") as zipref:\n",
    "            zipref.extractall(data_dir)\n",
    "            print(\"Unzip succesfully to:\",data_dir)\n",
    "        if delete:\n",
    "            os.remove(path)\n",
    "            print(\"Deleted zipfile.\")\n",
    "            return\n",
    "    else:\n",
    "        print(f\"This format file is not accepted: {path}\")\n",
    "\n",
    "data_dir = \"../data\"\n",
    "path = f\"{data_dir}/knowledge-base.zip\"\n",
    "\n",
    "unzip_file(path=path,data_dir=data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a605b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/knowledge-base\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(data_dir, \"knowledge-base\")\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34ac5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", 'your_api_key_here')\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "TEMPERATURE = 0.1\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e61cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit context retriever to use your own documents\n",
    "class ContextRetriever:\n",
    "    def __init__(self, docs_path=\"docs/*.txt\"):\n",
    "        self.docs_path = docs_path\n",
    "        self.documents = self.load_documents()\n",
    "\n",
    "    def load_documents(self):\n",
    "        documents = []\n",
    "        for file_path in glob.glob(self.docs_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                documents.append(file.read())\n",
    "        return documents\n",
    "\n",
    "    def retrieve(self, query, top_k=3):\n",
    "        # Simple keyword matching for demonstration purposes\n",
    "        scored_docs = [(doc, doc.lower().count(query.lower())) for doc in self.documents]\n",
    "        scored_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [doc for doc, score in scored_docs[:top_k] if score > 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
